# \# 20200323174640 Notes on Hilary Putnam\'s \"Brains in a Vat\" (1981) (Part 1)

\# Pebble+ Public\
20200323174640

\[image:AD4F2B09-0D20-40C1-9251-61B7509B0467-27513-000010D62DA41E4B/Pebbles.jpg\]

Notes on Hilary Putnam\'s \"Brains in a Vat\" (1981) (Part 1)

\#\# \*\*Summary:\*\*

Putnam defends the view that mental images do not represent anything in themselves. He also introduces the Brain in the Vats and Turing Machine thought experiments.

\~\*\*Introduction\*\*\~

\~Example of an ant crawling and creating a picture of Winston Churchill\~

The ant has accidentally created a picture of, or rather resembling, Winston Churchill.

\* The picture is not in itself a representation of any sort.\
\* Similarly, the word \"Winston Churchill" is not in itself a representation of any sort.

\*"If similarity is not necessary or sufficient to make something represent something else, how can anything be necessary or sufficient for this purpose?" (Putnam, 1981)\*

\* This means that if A and B are similar, it does not necessarily mean that A will represent B. How can anything represent B? Or how can- "one thing represent (or \'stand for\', etc.) a different thing?" (Putnam, 1981)

\~\*\*\*Premise 1: Similarity in images does not entail representation\*\*\*\~

The answer to this is that, for A to represent B, an \*Intention\* is necessary.

\~\*\*The Mind Being a Non-physical Matter by Virtue of Intentionality\*\*\~

\*"Some philosophers have, in the past, leaped from this sort of consideration to what they take to be a proof that the mind is essentially non-physical in nature." (Putnam, 1981)\*

\* Putnam is referring to Dualists who thought \*intentionality\* is a characteristic of non-physical mind. The dualists thought that physical objects cannot by themselves refer to something else.

\* \*Thoughts\* also have the characteristics of \*Intentionality\*. Human beings are capable of thoughts. Therefore, it must be human minds are non-physical.

Putnam hints that dualism postulates at mysterious powers to explain mind and intentionality. Even if one does not agree with Dualists, how can be one sure that intentionality and references are possible.

\~\*\*Magical theories of reference\*\*\~

\~The ant\'s drawing resembling Churchill\'s picture is a coincidence, not a representation\~

\> "\
\> "What is important to realize is that what goes for physical pictures also goes for mental images, and for mental representations in general; mental representations no more have a necessary connection with what they represent than physical representations do. The contrary supposition is a survival of magical thinking."

\> (Putnam, 1981)

\* This means that physical picture do not represent anything in itself.\
\* Similarly, mental image or mental representation do not represent anything in itself\
\* But magical thinking keeps this other perspective alive by insisting that mental images represent real objects

\~Explaining Mental Images through the example of alien humans seeing trees for the first time\~

\* Some alien humans have never seen trees. It would not be possible for them to imagine trees.

\* If a picture of a tree is dropped in that planet they still won't be able to know about real trees.\
\* For us the picture is a representation. For them it is an object. (Putnam would say it is a representation of a strange object. But how would they know it's a representation?)\
\* Suppose one of them has a mental image A. I have a mental image B of having seen the picture of the tree. Putnam would say, even if it happens that mental image A=B,

\* mental image A would represent a strange object and\
\* mental image B would represent a representation of tree

\* \*\*Objection:\*\* the mental images are representation of trees, because the mental image comes from real tree. (Causal chain from actual physical trees to mental images)

\* Therefore, if A=B then both are representation of trees.

\* \*\*Response to Objection:\*\* If the picture of a tree was instead a spilled paint accidentally causing a similarity to an image of a tree. This means no actual tree has a causal relationship with this spilled paint. In that case even if A=B, since for

\* the person having mental image A of a tree has no causal link with actual tree but a spilled paint\
\* And me having mental image of B of tree having causal link with actual tree

meaning than \*\*\*(Premise 1: Defended) similar mental image does not necessarily lead to representation.\*\*\*

\~Using the tree analogy to explain words\~

Using the analogy of trees Putnam says that similarly with words:

\* A discourse on paper about trees do not represent trees\
\* Monkeys accidentally writing perfect description of trees by hitting typewriter randomly (Sounds implausible)\
\* If a parrot memorised these words and said them regularly it still wouldn't represent anything.

\~\*\*Question:\*\*Represent to whom? My thoughts on this is that\~

1\. A discourse on trees do no represent a tree in itself but if someone \*intended\* to represent it, it would mean a representation of tree to that person. And if someone else knew about trees, then, that discourse would seem to be representing a tree to that other person.\
2. It is highly implausible that Monkeys will accidentally create a perfect description of trees even in thousand years, unless someone trained them. Here again, unless an external intention is involved, any detailed discursive representation cannot be created.\
3. Parrots can memorise these words about trees. They don't know they are representing a description of a tree, but for someone who knows the description and someone who taught them must have the intention in order to understand that there is a representation in the talking words of parrots.

\* It is then possible to know words but not know what it represents\
\* To make a word represent for a thinker, the word must refer to the actual experience of the thinker.

\*\*Similarly, for a mental image to represent a thought, the mental image must refer to an actual experience that is causally linked with the actual physical object.\*\*

\* but Putnam is saying that if monkeys did manage to type out a piece of \*Hamlet\* it would prove that a large and complicated verbal and visual system of representation still does not have any representation in itself. \*Thoughts and mental pictures\* do not \*intrinsically represent what they are about\*

\~\*\*The Case of the brains in a vat\*\*\~

\~Descriptions of how brains in a vat live\~

In this hypothetical scenario, my brains have been removed from my body and they are kept in a vat.

The vat is an electronic device which keeps me alive and makes me feel that I have a body. But everything I feel is really electronic impulses coming from that machine. And even though I think I move my body and do everything else, it is really the machine giving me the inputs. The evil scientist who controls the vat can give me any experience he wants and tamper with my memory.

The question is how do I know I am not in the machine?

Putnam elaborates the scenario by saying that everyone is in that vat except the scientist. Or perhaps it is such that machines are keeping us in alive in the vat. Also that the machines are giving us collective hallucinations and we think we have bodies when we are talking to each other but we are not actually. It's just impulses travelling from one brain to another.

\*"Suppose this whole story were actually true. Could we, if we were brains in a vat in this way, say or think that we were?" (Putnam, 1981)\*

\* Putnam asks if we were really brains in a vat, could we ever know that we were brains in a vat?\
\* Putnam says this is a self-refuting argument.

\*\*\~Statement:\~That \"The brains in a vat can know they are brains in a vat\" is self-refuting\*\*

\*A Self-refuting supposition is one whose being true implies its own falsity.\*

Examples:

\* All general statements are false. This is a general statement. Then this statement is false.

\* I do not exist. If I did not exist, how did I make this statement. Then this statement is false as well.

\* Putnam conceives of a possible world where humans are all 'brains in vat' and that they have the same experiences as we have.\
\* Putnam then claims that although people in the vats can think and say anything that we can think and say, they cannot, however, refer to what we can--- that they are brains in a vat.

\~\*\*Turing\'s Test\*\*\~

\~Description of Turing\'s Test\~

A \*\*Turing machine\*\* can converse with people like humans do. But it is so good at conversing that you don't see the machine while talking, you might mistake you are talking to a human being.

It is said that a computing machine is conscious if it can pass the Turing test. The idea behind this is that

\* because Turing machines can use words like human beings

\* they are conscious like human beings

This is the \*\*Dialogic Test of Competence for Consciousness\*\*

\~Using Dialogic Test of Competence for Reference\~

\*\*Putnam applies the Turing test to test the implications of references\*\*

\~The Turing Test of Reference\~

In this test, a machine refers to things as humans do.

The machine passes the test if it is able to refer to objects correctly and the human partner is unable to say whether he is taking to a machine or another human being.

Putnam asks whether this \*Turing test of Reference\* is a definitive Test for \*shared references\*?

: He answers that it is possible that the machine can refer to objects without understanding what it is referring to.

For this Putnam mentions the Word Processors that process thousands of words together, but still not refer to anything, thus they do not process any references, only words.

Putnam uses the analogy to apply on Brain-in-Vat worlders

\* That the brains in vats cannot refer to anything external at all

\~Putnam Argues how Programs cannot refer to anything\~

\* In a Turing test, one person is human and another player is a computer. If the human can't tell whether the computer is a human or not, the computer wins.\
\* If a computer plays a computer in a Turing test, who would win? How does a computer verify that another computer is human or not. It seems implausible because, the Turing computers are programmed to behave, but they are not trained to recognise. Thus, both will have discussion, but none will have the ability to verify who is human.\
\* Putnam says this is the evidence that computers cannot have references in itself.

\> "\
\> "Not only is it logically possible, though fantastically improbable, that the same machine could have existed even if apples, fields, and steeples had not existed; more important, the machine is utterly insensitive to the continued existence of apples, fields, steeples, etc. Even if all these things ceased to exist, the machine would still discourse just as happily in the same way. That is why the machine cannot be regarded as referring at all."

\> (Putnam, 1981)

\* Putnam is saying that machines could exist even if the apples did not exist. Machines are \*insensitive\* to the existence of the apples and trees. And the discourses machines make could go on even if trees had ceased to exist.

Thoughts:

I could exist even if the apples did not exist. I could not have seen apples and trees, and still could talk about apples as if I had seen the apples and trees.

\*\*Bibliography\*\*

Putnam, H. (1981) \*Brains in a vat\*. Cambridge: Cambridge: Cambridge University Press. doi:\[10.1017/CBO9780511625398.003\](https://doi.org/10.1017/CBO9780511625398.003).

https://v3.pebblepad.co.uk/components/builder/blockHero/defaultImages/Pebbles.jpg

\#Putnam \#Turing Test\# \#Blog \#1981\# \#Brains in Vat\#
