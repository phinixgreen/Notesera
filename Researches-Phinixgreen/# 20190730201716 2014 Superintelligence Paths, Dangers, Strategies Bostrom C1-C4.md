# \# 20190730201716 2014 Superintelligence Paths, Dangers, Strategies Bostrom C1-C4

\# \# 20190730201716 2014 Superintelligence: Paths, Dangers, Strategies Bostrom C1-C4\
\# 20190730201716 2014 Superintelligence: Paths, Dangers, Strategies Bostrom\
tags= Superintelligence, Artificial Intelligence, Bostrom, 2014\
PdfID= \# 20190627093141\
\# Formatted Reference\
Bostrom, N., 2014. Superintelligence: Paths, strategies and dangers.\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\#\# Chapter 1. Past Development and Present Capabilities

\#\#\# Growth model and big history\
\* Exponential growth in world wide history indicates the possibility of and emerging superintelligence

\#\#\# Great Expectations\
\* AI pioneer Alan Turing envisioned the Universal Computing Machine that may be capable of human like abilities\
\* They however gave less importance to the possibility that a Superintelligence entity could emerge from such abilities\
\* Seasons of hope and despair came where researches faced ups and down in enthusiasm about AI research\
\* Bayesian Theorem is used for learning algorithms which is numbering possible worlds like sand on a paper\
\* Utility Function is used for decision making algorithms which is numbered utility worlds leading to decision as the highest utility outcome\
\* Optimality Notion is the combination of Bayesian and Utility Function that is hard to achieve due to mathematical logic

\#\#\# State of the art\
\* Development of AI\
\* Chess, Go\
\* Speech recognition\
\* Image Recognition\
\* Translation\
\* Face recognition\
\* Digital marketing\
\* Theorem proving\
\* Automated Bomb disposal\
\* Intelligent Scheduling

\#\#\# Opinion about Future of Machine Intelligence\
\* HLMI/ AGI / Strong AI will arrive by 2022 - 2075\
\* Takeoff from HLMI to SI will take 2 - 30 years after AGI

\#\# Chapter 2. Paths to Superintelligence

Superintelligence is the any intellect that greatly exceeds cognitive performance of humans in virtually all domains of interest

\#\#\# Artificial Intelligence\
\* Blind evolutionary process can produce Human level general intelligence\
\* Moore's law can be applied to Supercomputer performance

\* Human brain as template proves great resources for designing superintelligence\
\* A seed AI should be able to understand its own working to bootstrap cognitive performance\
\* AI mind need not resemble a human mind

\#\#\# Whole Brain Emulation\
\* Uploading involves scanning human brain, computationally model the scan (Translate) and simulate the physical brain in computer\
\* This is the neuroscientific path to Superintelligence

\#\#\# Biological Cognition\
\* Enhancement through drugs\
\* Gene Editing could lead to Superintelligent humans

\#\#\# Brain-Computer Interface\
\* Direct BCI could lead to superhuman performances\
\* This has risks of damage to brain\
\* The hope for cyborg route is effective adaptation to the implant over time

\#\#\# Networking and Organization\
\* BCI looks unlikely path\
\* Bostrom argues that AI path to SI is more likely

\#\# Chapter 3. Forms of Superintelligence\
Machine substrate has greater potentials than bio-substrate. Three forms of superintelligence is envisioned.

\#\#\# Speed Superintelligence\
\* Faster computational power

\#\#\# Collective Superintelligence\
\* Smaller systems boosting the collective cognitive power of the SI\
\* Parts can extend the power of Collective SI

\#\#\# Quality Superintelligence\
\* Cognitive Traits that could have made us Superintelligent

\#\#\# Direct and Indirect Reach\
\* Indirect reach concerns the rise of Superintelligence from scratch\
\* Direct reach concerns the emergence of one form of SI from another

\#\#\# Sources of Advantage for Digital Intelligence\
\* Computational Speed\
\* Internal Communication Speed\
\* Storage Capacity\
\* Reliability\
\* Editability\
\* Duplicability\
\* Goal coordination\
\* Memory sharing\
\* New modules

\#\# Chapter 4. The kinetics of Intelligence Explosion\
\* After achieving Human equivalent reasoning ability how long till superintelligence?

\#\#\# Timing and speed of Takeoff\
\* If a machine with Human Level Intelligence is developed, how long before it takes off to SI?\
\* It might take a while to reach human baseline with access to information\
\* Reaching civilisation baseline should be quicker where the intelligence of SI should be equivalent to whole of civilization\
\* Take off from there could be-\
\* 1. Slow, in which case, there should be plenty of time to gather the news of take off\
\* 2. Fast, in which case, there won't be any time to gather news of the take off\
\* 3. Medium, in which case, it could be muddled by geopolitical turbulance\
\* Rate of Change in Intelligence = Optimization power (effort to make AI smarter) / Recalcitrance (System not responding to the design effort)\
\* Responsiveness = 1 / Recalcitrance

\#\#\# Recalcitrance\
\* Bostrom considers recalcitrance for different paths to SI\
\#\#\#\# Non-machine intelligence paths\
\* Cognitive enhacement through pharmacological + neuroscientific path has U shaped recalcitrance\
\* Genetic cognitive enhancement has U shaped recalcitrance- initially slow, fast in the middle, later slow again\
\* Recalcitrance in Brain-computer path is initially high, but later it could be difficult to make progress\
\* Recalcitrance in Network and Organization is initially high, later could be low

\#\#\#\# Emulation and AI paths\
\* Whole brain emulation can be initially difficult but later it might be harder to pursue due to resents from emulated minds and their supporters\
\* In the AI path SI recalcitrance could be initially high but later on the take off could be faster than any other mentioned method\
\* Content: Things that don't make up algorithmic structure (Skills, knowledge, percepts database)\
\* Hardware: Computational power on which algorithms run\
\* A case: Ability to read and understand at great speed. It could read and learn the whole knowledge base of the civilisation within days.\
\* In other words it can stand on the shoulders of the civilisation to leap towards greater intelligence\
\* Recalcitrance of amplifying collective or speed superintelligence is low\
\* in short term this could be dependent on funding\
\* in long term the AI could fund itself\
\* Hardware overhang\
\* When HLMI is created enough computing power may already be available\
\* Content Overhang\
\* Pre-made content could already exist by the time HLMI is achieved\
\* Algorithm Overhang\
\* Predesigned algorithmic enhancement may already exist but this is less likely to happen

\#\#\# Optimisation power and explosivity\
\* A fast take off does not require recalcitrance to be low\
\* A fast take off could also result from steadily increasing optimisation power\
\* If there is no deliberate attempt to stop it optimisation power of AGI will continue to increase during the take off\
\* Phase 1. for HLMI, more human effort may be needed to increase the optimisation power of AI to reach HLI\
\* Phase 2. once HLMI is reached, the AGI could improve its optimisation power on its own\
\* These analyses suggest that a fast or medium take off is more likely, slow take off cannot be possible.

\#Bostrom \#2014\# \#Superintelligence \#Artificial Intelligence\#
