# \# 20190719195723 2004 Coherent Extrapolated Volition Yudkowsky

\# \# 20190719195723 2004 Coherent Extrapolated Volition Yudkowsky\
\# 20190719195723 2004 Coherent Extrapolated Volition Yudkowsky\
tags= CEV, Yudkowsky, 2004, MIRI, Artificial Intelligence, Superintelligence\
PdfID= 20190717082144\
\# Formatted Reference\
Yudkowsky, E., 2004. Coherent extrapolated volition. Singularity Institute for Artificial Intelligence.\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\#\# Introduction

\*\*Friendly AI:\*\* An AI whose goal is aligned to the goals of human beings.

Friendly AI requires-\
Solving technical problems required for an abstract invariant (in a self-modifying goal system)\
"Choosing something nice to do with the AI."\
Designing a framework for an abstract invariant so that it does not lead to the extinction of human species

Explaining Abstract invariant-\
Abstract invariant is kind of fixed goal which if given to an AI could lead to wrong outcomes. For example: If one gives AI the goal to make humans smile. The AI may release laughing gas world wide, or may tile the entire solar system with smiley faces to make humans smile.

An AI with the capacity to easily wipe out humanity should have -\
\* Recursive self improvement: The machine improves from whatever resources it has, and with the improved capacity, improves even further and so on.

\* A coherent system based on self-modification. The self modification is probabilistic in nature. Does not maintain invariant optimization target (fixed target).

\* A theory of intelligence for deductive recursive self improvement. Doing without understanding what it is doing. Do what it is instructed.

\* Brute forcing the problem. This means testing on the basis of trial and error.

\#\# 2. Introducing Volition

Volition or will is the cognitive process by which an individual decides on and commits to a particular course of action. (Wikipedia)

To set an AIs volition, we need a dynamic for extrapolating (measuring by past experience or known data) AIs volition. To set an AIs volition aligned to our volition, the AI must be able to extrapolate our volition.\
This path could be achieved by feeding the complete readout of our brain state to the AI or an approximate model of our mind state.

\> "The FAI takes the knowledge of Fred's brainstate, and other knowledge possessed by the FAI (such as which box contains the diamond), does . . . something complicated . . . and out pops a construal of Fred's volition." (p.4)

Something complicated = Dynamic

\#\#\# 2.1 Spread, Muddle and Distance

\> "Spread describes cases where your extrapolated volition becomes unpredictable, in-\
tractable, or random."\
I may want to eat a banana now, I may not want to eat a banana three days later.

\> "Muddle measures self-contradiction, inconsistency, and cases of "damned if you do\
and damned if you don't."\
Cases where our volition runs into circularity.

\> "Distance measures how diﬃcult it would be to explain your volition to your current\
self, and the degree to which the volition was extrapolated by ﬁrm steps."\
Short distance: I agree with my extrapolated self\
Medium distance: I would need extra education and argument to agree with myself\
Long distance: I would find the extrapolated volition incomprehensible now\
Ground Zero: My actual decision

\#\#\# 2.2 Obvious moral Hazard of Volitionism as a Philosophy

\#\# 3. Coherent Extrapolated Volition\
The initial dynamic should implement a coherent extrapolated volition of humankind.\
Facets-\
\* Knowledge in distance

\* Knowledge in long distance

\* Beyond the current volitional spread

\* Collective Volition

\* Extrapolation now and extrapolation in the distance should converge, not diverge

\* Coherence of extrapolation removes muddled volition in terms of balance, concentration and strength of individual volitions.

\* The volitional dynamic should be consistent with personality

\* Volitional dynamic should be able to rewrite, renormalize or replace itself

\#\# 3.1 Coherence and influence

Coherence: Is the strong agreement between many extrapolated individual volition which are unmuddled and unspread in the domain of agreement and not countered by strong disagreement. Coherence\
\* Increases when humans agree

\* Decreases when humans disagree

\* Increases with stronger support for their wishes, with stronger emotion / philosophical argument

Coherence should be easy to counter than create.

Influence: Do things to achieve the goals on which our extrapolated volitions exhibit coherence

\> "A key point in building a young Friendly AI is that when the chaos in the system\
grows too high (spread and muddle both add to chaos), the Friendly AI does not guess.\
The young FAI leaves the problem pending and calls a programmer, or suspends, or\
undergoes a deterministic controlled shutdown. If humanity's volition is just too chaotic\
to extrapolate, the attempt to manifest our coherent extrapolated volition must fail visibly\
and safely." (p.9)

\#\# 3.2. Renormalizing the Dynamic

\* The initial dynamic for FAI should ask - "What dynamic for extrapolating a volition would we want?" or "What should the code of friendly AI look like?"

\> "There is an obvious analogy between construing a satisfactory initial dynamic for ex-\
trapolating a volition, and developing an Artiﬁcial Intelligence smart enough to improve\
its own code and bootstrap to superintelligence. Friendly AI theory treats the second\
problem as a special case of the ﬁrst." (p.9)

\#\# 3.3. Coherent Extrapolated Volition Is an Initial Dynamic

\> "Our coherent extrapolated volition should choose a small set of universal back-\
ground rules, not optimize every detail of individual lives." (p.10)

\> "The rules should not be inscrutable, and should prefer to operate scrutably, so that\
humans can understand, predict, and manipulate their world."

\> "The ruleset should be small enough that human beings can learn and understand\
all the rules in reasonable time."

\> "Auxiliary dynamics of a Nice Place to Live should not be included in the initial\
dynamic because:" they are complex, probabilistic, means to an end.

\#\# 4. Caring about Volition

\> "The dynamic of extrapolated volition refracts through that cognitive complexity of human minds which lead us to care about all the other things we might want; love, laughter, life, fairness, fun, sociality, self-reliance, morality, naughtiness, and anything else we might treasure. Whatever you care about---whatever it is of which you say, "XYZ is what we should care about"---it's your brain, a human brain, that produced that statement; and the air vibrating on your lips exists in a universe of cause and eﬀect. There is a physical explanation for why you said the words "XYZ." This does not devalue XYZ."

\> "CEV is a dynamic that passes through, and extrapolates, the human psychology of decision-making---including argument about morality, and human emotion, and the memes we argue together; everything that changes our choices. Any thoughts you have about morality are included as a special case of CEV extrapolating your thoughts."

\* CEV is about finding a common moral ground for humanity and provide it as a goal to the Friendly AI, so that when it becomes superintelligent, it aligns to the goals of humanity.

\> "Something about humanity's post-Singularity future will horrify us. It is guaranteed,\
no matter how good things get. It is guaranteed because things will get better."

Note:

Utility Function.

Berkeley\< Sanfrancisco \< San Jose \< Berkeley

\#Yudkowsky \#MIRI \#CEV \#2004\# \#Superintelligence \#Artificial Intelligence\#
