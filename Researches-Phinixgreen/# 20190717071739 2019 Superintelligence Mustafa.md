# \# 20190717071739 2019 Superintelligence Mustafa

\# \# 20190717071739 2019 Superintelligence Mustafa\
\# 20190717071739 2019 Superintelligence Mustafa\
tags= Superintelligence, Notes, Mustafa, 2019, Bostrom\
PdfID=\
\# Formatted Reference\
\[https://nickbostrom.com/superintelligence.html\](https://nickbostrom.com/superintelligence.html)\
\[https://en.wikipedia.org/wiki/Superintelligence\](https://en.wikipedia.org/wiki/Superintelligence)\
\[https://www.lesswrong.com/posts/EQFfj5eC5mqBMxF2s/superintelligence-23-coherent-extrapolated-volition\](https://www.lesswrong.com/posts/EQFfj5eC5mqBMxF2s/superintelligence-23-coherent-extrapolated-volition)\
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

\#\# What is Superintelligence?

Superintelligence is the property of a hypothetical agent which surpasses the cognitive capacities, ordinarily seen in intelligent agents in the real world.

It is a -\
\* problem solving system\
\* goal oriented\
\* has intelligent capacities in all broad domains of interest

\> According to Nick Bostrom (2014) \*\*\*superintelligence\*\*\* is \*\*any intellect\*\* that greatly \*\*exceeds the cognitive performance\*\* in all virtually \*\*all domains of interest.\*\*

Researchers believe superintelligence will ensue shortly afterwards the development of Artificial General Intelligence.

This means, the path from AGI to Superintelligence is an extremely steep learning curve.

AGI has-\
\* Steep learning curve\
\* Recursive self improvement \> Intelligent explosion

Artificial Intelligence is the likely path to AGI and SI.

AI has -\
\* Exponential Learning curve\
\* Modularity

\#\# Collective superintelligence\
Collective SI is a large number of separate reasoning systems, if communicated and coordinated well enough, could aggregate with far greater capability that any sub-agent

\#\# Design considerations for Ethical SI\
Proposed by Nick Bostrom, there are several design considerations for an Ethical SI\
1. Coherent extrapolated volition (CEV): an SI should have the value upon which humans should converge\
2. Moral Rightness: an SI should value moral rightness\
3. Moral Permissibility: an SI should value moral permissibility otherwise stay within the bounds of CEV.

\#2019\# \#Note \#Mustafa \#Bostrom \#Superintelligence
